{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP1juFUejv31kj1rLkcvY1x"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"JRM6b66Fkay9"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Load your dataset\n","df = pd.read_csv('email.csv')"]},{"cell_type":"code","source":["print(df.head())\n","df.info()\n","miss=df.isna().sum()\n","print(\"\\nMissing Values:\\n\",miss)\n","df.dropna(inplace=True)\n","print(\"\\nMissing Values:\\n\",df.isna().sum())\n","\n","\n","# Assuming the dataset has two columns: 'Message' and 'Category'\n","('spam' or 'ham')\n","# Map 'spam' to 1 and 'ham' to 0\n","df['Category'] = df['Category'].map({'spam': 1, 'ham': 0})\n","\n","# Check for missing values in the target variable\n","missing_values = df['Category'].isnull().sum()\n","print(f'Missing values in Category: {missing_values}')\n","\n","# Drop rows with missing values in 'Category'\n","df.dropna(subset=['Category'], inplace=True)\n","\n","# Extract features (X) and labels (y)\n","X = df['Message'] # Assuming 'Message' is the column name for the email text\n","y = df['Category']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y,\n","test_size=0.2, random_state=42)\n","\n","# Convert text data to numerical data using CountVectorizer\n","vectorizer = CountVectorizer()\n","X_train_transformed = vectorizer.fit_transform(X_train)\n","X_test_transformed = vectorizer.transform(X_test)\n","\n","# Train a Naive Bayes classifier\n","model = MultinomialNB()\n","model.fit(X_train_transformed, y_train)\n","\n","# Predict on the test data\n","y_pred = model.predict(X_test_transformed)\n","\n","# Calculate accuracy and print classification report\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy}')\n","print(classification_report(y_test, y_pred))\n","\n","# Function to predict if a message is spam or ham\n","def predict_message(message):\n","transformed_message = vectorizer.transform([message])\n","prediction = model.predict(transformed_message)\n","return 'spam' if prediction[0] == 1 else 'ham'\n","\n","# Example usage\n","message = input(\"Enter a message to classify as spam or ham: \")\n","print(f'The message is classified as: {predict_message(message)}')"],"metadata":{"id":"z2mudoJdkb_e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","\n","# Assume `results` is a dictionary that stores model performance from\n","previous steps.\n","# Example:\n","# results = {\n","#     'Naive Bayes': {'accuracy': 0.95, 'y_pred': y_pred_nb},\n","#     'SVM': {'accuracy': 0.93, 'y_pred': y_pred_svm},\n","#     'KNN': {'accuracy': 0.91, 'y_pred': y_pred_knn},\n","#     # Add other models...\n","# }\n","\n","# Model names and accuracy values\n","model_names = list(results.keys())\n","accuracy_scores = [results[model]['accuracy'] for model in results]\n","\n","# Bar Plot - Accuracy Comparison\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x=model_names, y=accuracy_scores, palette='magma')\n","plt.title('Accuracy Comparison of Different Models', fontsize=14)\n","plt.ylabel('Accuracy', fontsize=12)\n","plt.xlabel('Models', fontsize=12)\n","plt.xticks(rotation=45)\n","plt.show()\n","\n","# Scatter Plot - True vs Predicted Values for a specific model (e.g.,\n","Naive Bayes)\n","# You can change the model to visualize for another one\n","\n","y_test = np.array(y_test)  # Convert y_test to numpy array if it's a\n","Pandas Series\n","y_pred_nb = results['Naive Bayes']['y_pred']  # Assuming Naive Bayes\n","is one of the models\n","\n","plt.figure(figsize=(8, 6))\n","plt.scatter(range(len(y_test)), y_test, color='blue', label='True\n","Labels', alpha=0.6)\n","plt.scatter(range(len(y_pred_nb)), y_pred_nb, color='red',\n","\n","\n","label='Predicted Labels (Naive Bayes)', alpha=0.6)\n","plt.title('True vs Predicted Labels (Naive Bayes)', fontsize=14)\n","plt.xlabel('Samples', fontsize=12)\n","plt.ylabel('Spam/Ham (1 = Spam, 0 = Ham)', fontsize=12)\n","plt.legend()\n","plt.show()"],"metadata":{"id":"vvphf9dAkk5q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Logistic Regression Model\n","log_reg = LogisticRegression(max_iter=1000)\n","\n","# Train the model\n","log_reg.fit(X_train_transformed, y_train)\n","\n","# Predict\n","y_pred_logreg = log_reg.predict(X_test_transformed)\n","\n","# Evaluate the model\n","accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n","print(f\"\\n--- Logistic Regression ---\")\n","print(f\"Accuracy: {accuracy_logreg}\")\n","print(classification_report(y_test, y_pred_logreg))\n","\n","# Plot Confusion Matrix for Logistic Regression\n","plot_confusion_matrix(y_test, y_pred_logreg, \"Logistic Regression\")"],"metadata":{"id":"lZhPiptyklGY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Decision Tree Model\n","decision_tree = DecisionTreeClassifier()\n","\n","# Train the model\n","decision_tree.fit(X_train_transformed, y_train)\n","\n","# Predict\n","y_pred_dt = decision_tree.predict(X_test_transformed)\n","\n","# Evaluate the model\n","accuracy_dt = accuracy_score(y_test, y_pred_dt)\n","print(f\"\\n--- Decision Tree ---\")\n","print(f\"Accuracy: {accuracy_dt}\")\n","print(classification_report(y_test, y_pred_dt))\n","\n","# Plot Confusion Matrix for Decision Tree\n","plot_confusion_matrix(y_test, y_pred_dt, \"Decision Tree\")"],"metadata":{"id":"2mGHj8YkkzBG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","model_names = list(results.keys())\n","accuracy_scores = [results[model]['accuracy'] for model in results]\n","\n","# Bar Plot - Accuracy Comparison\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x=model_names, y=accuracy_scores, palette='magma')\n","plt.title('Accuracy Comparison of Different Models', fontsize=14)\n","plt.ylabel('Accuracy', fontsize=12)\n","plt.xlabel('Models', fontsize=12)\n","plt.xticks(rotation=45)\n","plt.show()"],"metadata":{"id":"c3TZYv5Xk5ed"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_message(message):\n","  transformed_message = vectorizer.transform([message])\n","  prediction = model.predict(transformed_message)\n","  return 'spam' if prediction[0] == 1 else 'ham'\n","   # Example usage\n","message = input(\"Enter a message to classify as spam or ham: \")\n","print(f'The message is classified as: {predict_message(message)}')"],"metadata":{"id":"LRBUEw0Mk9OX"},"execution_count":null,"outputs":[]}]}